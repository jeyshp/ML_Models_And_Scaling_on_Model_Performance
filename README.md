### Abstract
This experiment explores the impact of data scaling techniques and machine learning models on model
performance, with the goal of minimizing prediction error measured by root mean squared error (RMSE)
on three different datasets. Using a randomized blocked factorial design, we evaluated three scaling
methods (StandardScaler, MinMaxScaler, and RobustScaler) and three machine learning models (Linear
Regressor, Decision Tree Regressor, and K-NN Regression) across three datasets: Audit Data, Bike
Sharing Data, and California Housing Data. Our findings indicate that certain combinations of scaling
techniques and models outperform others, providing valuable insights into optimal preprocessing and
modeling strategies.
